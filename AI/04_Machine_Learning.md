# 교수님 코멘트

인공지능의 핵심!

기계학습 어떤 정리가 있었는지 러프하게 배울거고요

알고리즘 디테일한 작동 과정은 기계학습 시간에 배우겠죠

# 인공지능, 기계학습, 딥러닝의 관계

1. 인공지능

    - 인간이 가진 지적 능력을 컴퓨터를 통해 구현하는 기술

    - 인공지능의 구분

        - 강인공지능: 인간의 능력을 초월한 성능을 가진 AI

        - 약인공지능: 특정 영역에서 `도구로 사용하기 위해` 설계된 AI

2. 기계학습

    - 컴퓨터를 인간처럼 학습하게 함으로써

        - 인간의 도움 없이도 컴퓨터 스스로가 새로운 규칙을 발견할 수 있도록 하는 기술
    
    - 기계학습은 기본적으로 알고리즘을 이용해 데이터를 분석

        - 분석을 통해 학습

        - 학습한 내용을 기반으로 판단이나 예측을 함
    
    - 기계학습이 스스로 학습하여 데이터를 처리하는 과정

    a. 빅데이터를 입력

    b. 데이터를 분석하여 모델을 만듦

    c. 모델을 이용하여 의사결정 및 예측 등을 수행

3. 딥러닝

    - 인공신경망 ANN

        - Artificial Neural Network

        - 여러 뉴런이 서로 연결되어 있는 구조의 네트워크


    - 여러 `은닉층`을 가진 인공신경망을 사용 -> 기계학습을 수행하는 기술

    - 딥러닝의 딥 -> 연속된 신경망 층을 깊게 쌓는다는 의미

    - 이 신경망이 깊어질 수록 -> 성능 향상

```
이게 어떻게 학습이 되냐? 

원리는 

 

Node에.. 각각에 가중치라는 것이 생성이 되는데 

흰색 마스크 쓴 사람만 뽑고싶다고 보면 

마스크 쓴 사람들이 일단 눈에 ㄷㅡㄹ어오겠죠? 

근데 흰색 마스크에 가중치ㄹㅡㄹ 더 주게 되면.. 

좀 더 많이 학습을 하게 된다.. 

말고는 이사람이 여자인지 남자인지 마스크가 턱에가있는지 잘있는지.. 도 볼 수 있고 

 

인공지능 자체가 블랙박스 여서 

어떻게 학습되는지 알 수 없ㅇㅓ요 

왜 정확도가 90퍼 나온겨? 

이거 알 수 없어요.. 
```

## 기계학습과 딥러닝의 차이점

1. 인간의 개입 유무

    - 기계학습 -> 사람이 학습 데이터에 레이블(정답)을 알려주거나 or 데이터의 특징을 추출하는 등 어느 정도 개입

        - 레이블(정답) -> 딥러닝도 알려주기는 한다네요

    - 딥러닝 -> 인간의 개입 X, 컴퓨터 스스로 학습

![머신러닝 vs 딥러닝](/AI/img/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9Dvs%EB%94%A5%EB%9F%AC%EB%8B%9D.png)

>참고
특징 추출 Feature Extraction

2. 데이터 의존도 Data Dependencies

    - 딥러닝은 주어진 문제를 해결하기 위해 중요한 특징을 직접 추출

    - 그래서 데이터의 양이 충분하지 않으면 -> 정확한 특징을 추출할 수 없음

    - 반면, 충분한 양의 데이터가 주어진다면? -> 사람이 인지하지 못한 특징들까지도 찾아낼 수 있을 정도로 좋은 성능 발휘

3. 심층신경망의 사용 여부

    - 딥려닝은 심층신경망을 이용하여 -> 입력 데이터에서 특징을 추출 -> 스스로 결과를 토출

    - `심층신경망`을 사용하는 것은 -> 딥러닝만의 뚜렷한 특징

        - 머신러닝은 `단층신경망`

    - 많으면 많을 수록 성능 up

    - 학습에 걸리는 시간도 up

![머신러닝vs딥러닝2](/AI/img/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9Dvs%EB%94%A5%EB%9F%AC%EB%8B%9D2.png)

# 기계학습을 사용하는 이유

## 기존 프로그래밍의 한계

..그런게 있군용

## 기계학습의 유용성

- 기존 프로그래밍 -> 빠른 의사결정이 필요한 시기에 적절하지 않음

- 그래서 이를 해결하기 위해..

- 대용량 데이터와 많은 변수가 관련되어 있고 -> 기존에 사용했던 규칙의 프로그램으로는 복잡한 작업 or 문제를 해결할 수 없을 때 -> 기계학습 매우 유용

# 기계학습의 종류

## 기계학습의 분류

- 지도학습: 예측이나 분류를 위해 사용

    - 문제와 답을 함께 학습

    - 미지에 문제에 대한 올바른 답을 예측하도록

- 비지도학습: 군집을 위해 사용

    - 조력자의 도움 없이, 컴퓨터 스스로 학습

    - 컴퓨터가 훈련 데이터를 이용하여 -> 데이터들 간 규칙성을 찾음

    - 지도학습에서.. 입력데이터 x와 레이블 y의 관계를 파악했던 것과 달리

        - 비지도학습은 x 간의 관계를 스스로 파악

- 강화학습: 환경에서 취하는 행동에 대한 보상을 이용, 학습 진행

    - 자신이 한 행동에 대해 보상을 받으며 학습

    - 컴퓨터가 주어진 상태에 대해 -> 최적의 행동을 선택하도록 학습

    - 강화학습이 딥러닝인건 아니다? 딥러닝은 그 안에.. 알고리즘 중 하나다?

    - 상은 최대화, 벌은 최소화

    - 개념들

        - 에이전트 Agent: 주어진 문제 상황에서 행동하는 `주체`

        - 상태 State: 현재 시점에서의 상황

        - 행동 Action: 플레이어가 취할 수 있는 선택지

        - 보상 Reward: 플레이어가 어떤 행동을 했을 때, 따라오는 이득

        - 환경 Environment: 문제 그 자체를 의미

        - 관찰 Observation: 에이전트가 수집한 (보고 듣는) 환경에 대한 정보
    
    - 주어진 환경에서 에이전트가 선택한 행동에 따라 -> 그 행동이 옳은 선택이면? -> 상을 받고 -> 잘못된 선택이면? -> 벌을 받음

    - 에이전트가 상태를 계속 주시.. 보상이 높은 쪽으로 학습(행동)하게 됨

![강화학습 개념](/AI/img/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EA%B0%9C%EB%85%90.png)

# 기계학습 알고리즘의 유형

## 학습 알고리즘 유형

- 분류

    - 이진 분류 Binary Classification

    - 다중 분류 Multiclass Classification

```
One versus rest 

하나, 그리고 나머지.. 

 

파란색 데이터 타겟으로 하고 

그 나머지 데이터를 두고 

1, 2로 두고.. 

분류 

 

빨간것도 빨간것과 그 나머지로 분류하고 

분류분뷰뷸류 
```

>딥러닝은 이런거 보인다 안보인다?
안보인다~

### 분류

- 분류에 해당하는 알고리즘

    - K-최근접 이웃 KNN

        - 새로운 데이터가 들어왔을 때 -> 기존 데이터의 그룹(K개의 그룹) 중 어떤 그룹에 속하는지 분류하는 알고리즘

        - 하지만, 어떤 하이퍼파라미터가 분석에 적합한지는 불분명

        - 데이터 각각의 특성에 맞게 `연구자가 임의로 선정`해야 함

    - 서포트 벡터 머신 SVM

        - 두 분류 사이의 여백을 의미하는 마진 margin 을 최대화

        - 마진을 극대화하는 선을 찾아 분류

        - 마진이 크면 클수록, 새로운 데이터가 들어오더라도 잘 분류할 가능성이 높아짐

        - 사용 방법이 쉽고, 예측 정확도가 높다

        - 근데.. 모델 구축에 시간이 오래 걸리고.. 설명력이 떨어지는 단점

            - 결정 경계

            - 서포트 벡터

            - 마진

    - 의사결정나무 Decision Tree

        - 의사결정 규칙을 tree 형태로 분류

        - 상위 노드에서 시작하여 -> 분류 기준값에 따라 하위 노드로 확장

        - 나무 모양이에요

            - 분석 과정이 직관적 & 이해 용이

            - 블랙박스가 아니에요! 분석 과정을 눈으로도 관측할 수 있음

            - 그래서 결과에 대한 명확한 설명 필요할 때 많이 사용

### 군집화

- 군집 cluster

    - 비슷한 특징을 가진 데이터들의 집단

- 군집화 clustering

    - 데이터가 주어졌을 때, 그 데이터들을 유사한 정도에 따라 -> 군집으로 분류

    - 다양한 데이터들이 서로 섞여 -> 군집화 과정을 진행

- K-평균 군집화

    - K-Means Clustering

    - 'K'는 주어진 데이터로부터 묶여질 그룹, 군집의 수

    - 'Means'는 각 군집의 중심과 데이터들의 평균 거리를 의미

    - 클러스터의 중심을 중심점 centroids 이라고 함

### 강화학습 기술

1. 모델이 없는 알고리즘

    - 모델기반 알고리즘은 현재의 상태에서 -> 어떤 행동을 했을 때 -> 다음의 상태가 될 확률을 의미

    - 알파고도 얘 래요

        - 해당 루트가 최적인지, 최악인지

    - 에이전트가 행동을 통해 받게 되는 보상을 최대로 하는 정책 policy을 찾는 것

# 기계학습 적용 예시

- 기계학습에서 데이터의 중요성

    - 데이터는 학습의 연료

    - 데이터가 없으면? 기계학습 자체가 불가능

- 기계학습의 전형적인 과정

    - 실제에서는 더 다양한 형태로 나타나겠지만~

    - 데이터 수집 -> 특징 추출 -> 모델링 -> 예측

    - 데이터만 좋은면 학습은 뭐~

- scikit-learn 라이브러리

# 성능 측정

- 객관적인 성능 측정의 중요성

    - 모델 선택할 때 중요

    - 현장 설치 여부 결정 시 중요

- 일반화 generalization 능력

    - 학습에 사용하지 않았던 새로운 데이터에 대한 선으

    - 가장 확실한 방법은 -> 실제 현장에 설치하고 성능 측정

        - 근데 이건 비용이..

    - 주어진 데이터를 분할하여 사용하는 지혜 필요

# 혼동 행렬과 성능 측정 기준

## 혼동 행렬 confusion matrix

- 부류 별 옳은 분류 vs 틀린 분류 의 개수를 기록한 행렬

- 이진 분류에서 긍정 vs 부정

- 참 긍정 TP, 거짓 부정 FN, 거짓 긍정 FP, 참 부정 TN

## 성능 측정 기능

- 정확률 accuracy

    - 부류가 불균형일 때 성능을 제대로 반영하지 못함

```
정확률 = 맞힌 샘플 수 / 전체 샘플 수
```

- 특이도 specifficity 와 민감도 sensitivity

    - 의료에서 주로 사용

```
특이도 = TN / (TN + FP)

민감도 = TP / (TP + FN)
```

- 정밀도 precision 와 재현율 recall

```
정밀도 = TP / (TP + FP)

재현율 = TP / (TP + FN)
```

# 훈련/검증/테스트 집합으로 쪼개기

- 훈련 집합 VS 테스트 집합

    - 훈련 집합: 
        
        - 기계 학습 모델을 학습하는데 쓰는 데이터

        - 특징 벡터와 레이블 정보 모두 제공
    
    - 테스트 집합:

        - 학습을 마친 모델의 성능을 측정하는데 쓰는 데이터

        - 예측 시, 특징 벡터 정보만 제공

        - 예측 결과를 가지고 정확률을 측정할 때 레이블 정보 사용

- 모델 선택 포함: 훈련 / 검증 / 테스트

- 모델 선택 제외: 훈련 / 테스트

# 교차 검증

- 훈련/테스트 집합 나누기의 한계

    - `우연히` 높은 정확률 or `우연히` 낮은 정확률 발생 가능성

- k-겹 교차 검증

    - 훈련 집합을 k개의 부분집합으로 나누어 사용

    - 한 개를 남겨두고 k-1개로 학습한 다음

    - 남겨둔 것으로 성능 측정

    - k개의 성능을 평균하여 신뢰도 높임

# 인공지능 제품의 설계와 구현

- 인공지능 제품의 핵심

    - 데이터를 읽고 모델링과 예측을 수행

    - 붓꽃 영상을 획득하고 특징을 추출하는 컴퓨터 비전 모듈을 전처리로 붙이면? -> 붓꽃 인식 프로그램 완성

- 실용적인 시스템 사례

    - 과일 등급 분류

    - 딸기 따는 로봇

# 기계학습의 주요 도전 과제

- 많은 데이터 확보

    - 컴퓨터는 인간과 다르게 0, 1이라는 숫자만 인식할 수 있죠?

    - 즉, 이미지 안의 객체를 숫자로 표현해야 하고 -> 객체 중에서도 자동차만을 인식할 수 있도록 -> 별도의 처리(기계학습의 가중치(weight)) 를 해주어야 한다는 뜻

    - 이렇게 복잡한 과정을 거치면서 -> 다양한 유형의 자동차를 정확하게 인식하기 위해서는 -> `수많은 데이터가 필요함`

- 과적합 현상 overfitting

    - 훈련 데이터를 너무 과하게 학습하여 실제 데이터를 분석할 때는 성능이 좋지 못한 것을 의미

    - 문제의 복잡도에 비해 데이터가 현저히 부족한 경우 -> 즉, 문제가 정의 된 전체 공간을 학습 데이터가 아우르지 못하고 일부 경우에만 집중했을 때 발생

    - 하나의 실제값을 불러왔을 때, 실제값과 모델이 내놓은 예측값의 차이인 `오차`가 가장 작은 그래프가 좋은 그래프

- 유연성

    - 기계학습은 유연성이 부족함

        - 데이터로 시작해서 데이터로 끝나기 때문에..
    
    - 다른 사람이 만들어 놓은 모델 -> 재활용이 가능하더라도.. -> 데이터는 공유 어렵죠?

        - 실제로 공유 된 데이터를 사용할 수도 있지만, 분석하고자 하는 변수 중 일부가 누락된 경우가 많기 때문에 ->공유 된 데이터를 이용한 분석은 그 목적에서 벗어난 경우가 많다..

    - 따라서 제대로 학습을 하려면 -> 원하는 결과를 위한, 목적에 맞는 '나만의 데이터'가 필요함

        - 결국 데이터가 없다면? 기계학습 알고리즘도, 딥러닝 알고리즘도.. 적용이 어려운 거죠
